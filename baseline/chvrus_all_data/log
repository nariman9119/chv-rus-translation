[2020-02-26:14:52:05:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (100, 100)
[2020-02-26:14:52:05:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:14:52:05:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2020-02-26:14:52:05:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:14:52:05:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2020-02-26:14:52:05:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['chv.all.train.bpe']
[2020-02-26:14:52:06:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5611/5611/5611/5615 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:14:52:06:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['rus.all.train.bpe']
[2020-02-26:14:52:08:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5715/5715/5715/5719 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:14:52:08:INFO:sockeye.data_io:prepare_data] Preparing data.
[2020-02-26:14:52:08:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/home/nariman9119/sockeye/chvrus_all_data/vocab.src.0.json"
[2020-02-26:14:52:08:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/home/nariman9119/sockeye/chvrus_all_data/vocab.trg.0.json"
[2020-02-26:14:52:11:WARNING:sockeye.data_io:parallel_iterate] Parallel reading of sequences skipped 1 elements
[2020-02-26:14:52:11:INFO:sockeye.data_io:analyze_sequence_lengths] 84672 sequences of maximum length (100, 100) in 'chv.all.train.bpe' and 'rus.all.train.bpe'.
[2020-02-26:14:52:11:INFO:sockeye.data_io:analyze_sequence_lengths] Mean training target/source length ratio: 1.06 (+-0.20)
[2020-02-26:14:52:11:INFO:sockeye.data_io:prepare_data] Buckets: [(9, 10), (18, 20), (27, 30), (36, 40), (45, 50), (54, 60), (63, 70), (72, 80), (81, 90), (90, 100), (99, 100), (100, 100)]
[2020-02-26:14:52:11:INFO:sockeye.data_io:prepare_data] 84672 samples will be split into 1 shard(s) (requested samples/shard=1000000, min_num_shards=1).
[2020-02-26:14:52:17:WARNING:sockeye.data_io:parallel_iterate] Parallel reading of sequences skipped 1 elements
[2020-02-26:14:52:17:INFO:sockeye.data_io:log] Tokens: source 2122719 target 2227070
[2020-02-26:14:52:17:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-26:14:52:17:INFO:sockeye.data_io:log] 84672 sequences across 12 buckets
[2020-02-26:14:52:17:INFO:sockeye.data_io:log] 1801 sequences did not fit into buckets and were discarded
[2020-02-26:14:52:20:INFO:sockeye.data_io:load] Created bucketed parallel data set. Introduced padding: source=16.5% target=21.0%)
[2020-02-26:14:52:20:INFO:sockeye.data_io:log] Tokens: source 2122719 target 2227070
[2020-02-26:14:52:20:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-26:14:52:20:INFO:sockeye.data_io:log] 84672 sequences across 12 buckets
[2020-02-26:14:52:20:INFO:sockeye.data_io:log] 1801 sequences did not fit into buckets and were discarded
[2020-02-26:14:52:20:INFO:sockeye.data_io:prepare_data] Writing '/home/nariman9119/sockeye/chvrus_all_data/shard.00000'
[2020-02-26:14:52:20:INFO:sockeye.data_io:prepare_data] Writing data info to '/home/nariman9119/sockeye/chvrus_all_data/data.info'
[2020-02-26:14:52:20:INFO:sockeye.data_io:prepare_data] Writing data config to '/home/nariman9119/sockeye/chvrus_all_data/data.config'
[2020-02-26:15:00:08:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (100, 100)
[2020-02-26:15:00:08:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:00:08:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2020-02-26:15:00:08:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:00:08:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2020-02-26:15:00:08:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['chv.all.train.bpe']
[2020-02-26:15:00:09:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5611/5611/5611/5615 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:15:00:09:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['rus.all.train.bpe']
[2020-02-26:15:00:10:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 93, in <module>
    main()
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 32, in main
    prepare_data(args)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 74, in prepare_data
    pad_to_multiple_of=args.pad_vocab_to_multiple_of)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 301, in load_or_create_vocabs
    num_pointers=num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 231, in load_or_create_vocab
    num_pointers=num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 57, in build_from_paths
    return build_vocab(chain(*files), num_words, min_count, pad_to_multiple_of, num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 80, in build_vocab
    raw_vocab = Counter(token for line in data for token in utils.get_tokens(line) if not is_symbol(token))
  File "/usr/lib/python3.6/collections/__init__.py", line 535, in __init__
    self.update(*args, **kwds)
  File "/usr/lib/python3.6/collections/__init__.py", line 622, in update
    _count_elements(self, iterable)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 80, in <genexpr>
    raw_vocab = Counter(token for line in data for token in utils.get_tokens(line) if not is_symbol(token))
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/utils.py", line 331, in get_tokens
    for token in line.rstrip().split():
KeyboardInterrupt
[2020-02-26:15:00:48:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (100, 100)
[2020-02-26:15:00:48:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:00:48:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2020-02-26:15:00:48:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:00:48:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2020-02-26:15:00:48:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['chv.all.train.bpe']
[2020-02-26:15:00:50:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5611/5611/5611/5615 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:15:00:50:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['rus.all.train.bpe']
[2020-02-26:15:00:51:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 93, in <module>
    main()
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 32, in main
    prepare_data(args)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/prepare_data.py", line 74, in prepare_data
    pad_to_multiple_of=args.pad_vocab_to_multiple_of)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 301, in load_or_create_vocabs
    num_pointers=num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 231, in load_or_create_vocab
    num_pointers=num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 57, in build_from_paths
    return build_vocab(chain(*files), num_words, min_count, pad_to_multiple_of, num_pointers)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 80, in build_vocab
    raw_vocab = Counter(token for line in data for token in utils.get_tokens(line) if not is_symbol(token))
  File "/usr/lib/python3.6/collections/__init__.py", line 535, in __init__
    self.update(*args, **kwds)
  File "/usr/lib/python3.6/collections/__init__.py", line 622, in update
    _count_elements(self, iterable)
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 80, in <genexpr>
    raw_vocab = Counter(token for line in data for token in utils.get_tokens(line) if not is_symbol(token))
  File "/home/nariman9119/.local/lib/python3.6/site-packages/sockeye/vocab.py", line 79, in <lambda>
    is_symbol = lambda token: (token in vocab_symbols_set)
KeyboardInterrupt
[2020-02-26:15:11:48:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (100, 100)
[2020-02-26:15:11:48:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:11:48:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2020-02-26:15:11:48:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2020-02-26:15:11:48:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2020-02-26:15:11:48:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['chv.all.train.bpe']
[2020-02-26:15:11:49:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5611/5611/5611/5615 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:15:11:49:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): ['rus.all.train.bpe']
[2020-02-26:15:11:50:INFO:sockeye.vocab:build_vocab] Vocabulary: types: 5715/5715/5715/5719 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[2020-02-26:15:11:50:INFO:sockeye.data_io:prepare_data] Preparing data.
[2020-02-26:15:11:50:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/home/nariman9119/sockeye/chvrus_all_data/vocab.src.0.json"
[2020-02-26:15:11:50:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/home/nariman9119/sockeye/chvrus_all_data/vocab.trg.0.json"
[2020-02-26:15:11:54:WARNING:sockeye.data_io:parallel_iterate] Parallel reading of sequences skipped 1 elements
[2020-02-26:15:11:54:INFO:sockeye.data_io:analyze_sequence_lengths] 84672 sequences of maximum length (100, 100) in 'chv.all.train.bpe' and 'rus.all.train.bpe'.
[2020-02-26:15:11:54:INFO:sockeye.data_io:analyze_sequence_lengths] Mean training target/source length ratio: 1.06 (+-0.20)
[2020-02-26:15:11:54:INFO:sockeye.data_io:prepare_data] Buckets: [(9, 10), (18, 20), (27, 30), (36, 40), (45, 50), (54, 60), (63, 70), (72, 80), (81, 90), (90, 100), (99, 100), (100, 100)]
[2020-02-26:15:11:54:INFO:sockeye.data_io:prepare_data] 84672 samples will be split into 1 shard(s) (requested samples/shard=1000000, min_num_shards=1).
[2020-02-26:15:11:59:WARNING:sockeye.data_io:parallel_iterate] Parallel reading of sequences skipped 1 elements
[2020-02-26:15:11:59:INFO:sockeye.data_io:log] Tokens: source 2122719 target 2227070
[2020-02-26:15:11:59:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-26:15:11:59:INFO:sockeye.data_io:log] 84672 sequences across 12 buckets
[2020-02-26:15:11:59:INFO:sockeye.data_io:log] 1801 sequences did not fit into buckets and were discarded
[2020-02-26:15:12:02:INFO:sockeye.data_io:load] Created bucketed parallel data set. Introduced padding: source=16.5% target=21.0%)
[2020-02-26:15:12:02:INFO:sockeye.data_io:log] Tokens: source 2122719 target 2227070
[2020-02-26:15:12:02:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-26:15:12:02:INFO:sockeye.data_io:log] 84672 sequences across 12 buckets
[2020-02-26:15:12:02:INFO:sockeye.data_io:log] 1801 sequences did not fit into buckets and were discarded
[2020-02-26:15:12:02:INFO:sockeye.data_io:prepare_data] Writing '/home/nariman9119/sockeye/chvrus_all_data/shard.00000'
[2020-02-26:15:12:03:INFO:sockeye.data_io:prepare_data] Writing data info to '/home/nariman9119/sockeye/chvrus_all_data/data.info'
[2020-02-26:15:12:03:INFO:sockeye.data_io:prepare_data] Writing data config to '/home/nariman9119/sockeye/chvrus_all_data/data.config'
